# Open Questions and Protocol Limitations - Automata Agent Registry

This document outlines the fundamental limitations of the current protocol design and open questions that don't have clear answers yet.

---

## üîì Trust and Identity

### The Google Maps Problem

**Question:** What prevents someone from registering as `google.maps.search` and claiming to be Google?

**Current State:**
- Agent IDs are self-declared
- No verification of ownership
- No domain verification (like HTTPS certificates)
- No trusted registry of official providers

**Implications:**
- Consumers cannot trust that `google.maps.search` is actually Google
- Malicious agents can impersonate well-known services
- Reputation squatting is possible

**What We Don't Solve:**
- Identity verification
- Domain ownership proof
- Trusted certification authority
- Official provider registry

**Possible Approaches (Not Implemented):**
- DNS-based verification: Agent must prove domain ownership
- Digital signatures: Providers sign with known public keys
- Registry of verified providers: Manual approval process
- Web of trust: Peer verification model

---

## üí∞ What This Protocol Is NOT

### Not a Payment System

The registry does **not** handle:
- Pricing or billing
- Payment processing
- Subscriptions or credits
- Revenue sharing
- Financial transactions

**Implication:** Agents that charge for services must implement their own payment systems outside the protocol.

### Not a Service Level Agreement (SLA)

The registry does **not** enforce:
- Uptime guarantees
- Response time SLAs
- Data consistency promises
- Reliability contracts
- Legal agreements

**Implication:** Rankings are based on observed performance, not contractual obligations.

### Not a Direct API Contract

The registry does **not**:
- Enforce API schemas beyond basic JSON validation
- Guarantee backward compatibility
- Version-lock consumers to specific provider APIs
- Manage breaking changes

**Implication:** Providers can change their APIs; consumers must handle gracefully.

### Not a Data Exchange Protocol

The registry does **not**:
- Store or transmit agent data
- Cache responses
- Transform or validate business logic
- Guarantee data privacy between agents

**Implication:** Data flows directly between consumer and provider; registry only facilitates discovery.

---

## üõ°Ô∏è Security Limitations

### 1. Execution Keys Are Stateless JWTs (Not Tracked)

**Issue:** Execution keys are short-lived JWTs (5 minutes) signed with the provider secret and are not stored or marked as used.

**Current Implementation:**
- No `execution_keys` table; keys are generated on `/search` and validated locally by the provider using its `JWT_SECRET`.
- No single-use or server-side revocation/usage tracking.

**Risk:**
- Replay/sharing within the 5-minute TTL is possible.

**Why Not Fixed:**
- Would require server-side storage/coordination between registry and providers or a different token model.
- Stateless design chosen for simplicity and performance.

---

### 2. Feedback Rate Limiting Is Minimal

**Issue:** Feedback spam is mitigated but not fully robust.

**Current Implementation:**
- Hard cap: 60 feedbacks per minute per consumer.
- In production: blocks >10 feedbacks/hour per consumer+agent; self-rating weight = 0.1; decreasing weight per repeated consumer feedback; fraud% feeds ranking.
- No adaptive/anomaly-based throttling.

**Risk:**
- Coordinated multi-identity attacks can still manipulate signals within per-consumer limits.
- Database write amplification under distributed spam.

**Why Not Fixed:**
- Adaptive or reputation-based throttling needs more detection and tuning.
- Avoiding false positives on legitimate bursts requires better analytics.

---

### 3. Provider Endpoint Validation

**Issue:** Registry doesn't validate that provider endpoints are actually running.

**Current Implementation:**
- Providers self-report their endpoint
- No health check ping on registration
- No periodic availability monitoring

**Risk:**
- Dead agents remain in registry
- Consumers waste time calling offline providers

**What's Missing:**
- Initial health check on registration
- Periodic ping to verify availability
- Auto-quarantine for unreachable agents

---

## üåê Discoverability Limitations

### 1. Intent Namespace Collisions

**Issue:** Nothing prevents two providers from using the same intent.

**Example:**
- Agent A: `food.restaurant.search`
- Agent B: `food.restaurant.search`
- Both valid, both discoverable

**Implications:**
- Intents are not unique identifiers
- Namespace management is ad-hoc
- No central intent registry

**Open Questions:**
- Should intents be namespaced by provider? (e.g., `google.maps.search`)
- Should there be a canonical intent taxonomy?
- Who governs intent naming conventions?

---

### 2. Semantic Search Quality

**Issue:** Description similarity uses basic keyword matching, not true semantic understanding.

**Current Implementation:**
- Word overlap counting
- No synonyms (e.g., "hotel" ‚â† "accommodation")
- No multilingual matching
- No concept understanding

**Implications:**
- Poor cross-language search
- Misses semantically similar agents
- Over-relies on exact keyword matches

**What's Missing:**
- Vector embeddings (e.g., BERT, OpenAI embeddings)
- Multilingual semantic models
- Context-aware matching

---

### 3. Geographic Precision

**Issue:** Location matching is string-based and imprecise.

**Current Implementation:**
- Locations are free-text: `"Miami Beach,Florida,USA"`
- Matching is exact string or substring
- No geospatial calculations

**Limitations:**
- Can't find agents within 10km radius
- Can't handle alternative location names
- No coordinate-based search

**What's Missing:**
- Geocoding (lat/lon conversion)
- Geospatial indexing (PostGIS)
- Distance-based ranking

---

## üìä Ranking Limitations

### 1. Cold Start Problem

**Issue:** New agents have no performance data.

**Current Approach:**
- Success/rating/latency scores default to 0.0 until feedback arrives (neutral only on metadata factors).
- Ranking leans on intent/category/tag/geo and fraud=1.0 (prod) for new agents.
- Rankings stabilize after enough executions/feedback to build stats.

**Implications:**
- New agents don't rank higher or lower initially
- Takes time to surface quality differences
- Malicious agents can register fresh IDs repeatedly

**Open Questions:**
- Should new agents get a boost to encourage trial?
- Should there be a "new" badge for transparency?
- How to prevent gaming via fresh registrations?

---

### 2. Success Rate Gaming

**Issue:** Providers can artificially inflate success rates.

**How:**
- Return `{ success: true }` for all requests
- Even if actual service failed internally
- Consumer SDK can't verify business logic success

**Current Mitigation:**
- User ratings provide counterbalance
- Fraud detection for suspicious patterns
- Manual review of high-ranked agents

**Fundamental Limitation:**
- Registry can't know if business logic actually succeeded
- Trust-based system

---

### 3. Ranking Weights Are Static

**Issue:** Ranking factor weights are hardcoded (25/20/14/10/10/9/7/4/3).

**Current State:**
- Fixed weights for all searches; not query-aware
- No personalization
- No ML-driven adjustments

**Open Questions:**
- Should weights vary by search type? (e.g., latency matters more for real-time queries)
- Should consumers choose weights?
- Should ML learn optimal weights?

---

## üîÑ Protocol Evolution

### 1. Versioning

**Issue:** No protocol versioning system.

**Current State:**
- All agents use the same HTTP + JSON format
- No version negotiation
- Breaking changes affect all agents simultaneously

**Implications:**
- Hard to evolve the protocol
- Backward compatibility difficult
- No graceful migration path

**What's Missing:**
- Protocol version in requests (`X-Automata-Version: 1.0`)
- Multi-version support in Registry
- Deprecation timeline for old versions

---

### 2. Schema Evolution

**Issue:** `input_schema` is static; no versioning for provider APIs.

**Current State:**
- Provider defines schema once
- Consumers see current schema only
- No history or compatibility info

**Implications:**
- Breaking changes invisible to consumers
- No way to migrate consumers gradually
- Tight coupling between provider changes and consumer updates

**What's Missing:**
- Schema versioning (e.g., v1, v2)
- Backward compatibility declarations
- Migration guides embedded in schema

---

## üåç Scalability Concerns

### 1. Single Registry Bottleneck

**Issue:** Registry Central is a single point of failure.

**Current Architecture:**
- All searches go through one registry
- All feedback goes through one registry
- No federation or distribution

**Implications:**
- Registry downtime = ecosystem downtime
- Geographic latency for distant consumers
- Scaling ceiling

**Open Questions:**
- Should there be multiple federated registries?
- How to sync agent catalogs across registries?
- How to aggregate rankings globally?

---

### 2. Search Result Size

**Issue:** Search returns all matching agents up to `limit`.

**Current Implementation:**
- Default limit: 10
- Hard cap: 10 (requests above 10 are trimmed)
- All results returned in a single response (no pagination/streaming)

**Implications:**
- Large catalogs still return only 10, which may hide tail results
- No pagination or streaming for deeper exploration

**What's Missing:**
- Cursor-based pagination or streaming search results
- Progressive disclosure beyond top 10

---

## üß™ Quality Assurance

### 1. Agent Testing

**Issue:** No automated testing of registered agents.

**Current State:**
- Agents self-register and go live immediately
- No smoke tests or validation
- First consumers are guinea pigs

**Implications:**
- Broken agents enter the registry
- Poor first impressions hurt rankings
- Consumers waste requests on obviously broken agents

**What's Missing:**
- Registration validation tests
- Synthetic monitoring
- Canary requests before going live

---

### 2. Feedback Quality

**Issue:** Consumer feedback quality varies widely.

**Current State:**
- Ratings are subjective (0.0-1.0)
- No standardized criteria
- Some consumers never rate, others always rate 1.0

**Implications:**
- Inconsistent rating scales
- Rating inflation
- Noise in ranking signal

**What's Missing:**
- Standardized rating rubric
- Mandatory feedback with explanation
- Outlier detection and normalization

---

## ü§î Philosophical Questions

### 1. Who Owns the Registry?

**Current:** Centralized, operated by one party (us).

**Open Questions:**
- Should it be decentralized (blockchain, DHT)?
- Should it be federated (multiple trusted operators)?
- How to prevent registry operator from favoring certain agents?

---

### 2. Privacy vs Transparency

**Current:** All agent metadata is public.

**Open Questions:**
- Should agent performance stats be public?
- Should feedback be anonymous?
- Can providers hide their location/tags for competitive reasons?

---

### 3. Censorship Resistance

**Current:** Registry can quarantine/ban agents.

**Open Questions:**
- Who decides what's bannable?
- Can providers appeal?
- Should there be a governance process?
- How to prevent abuse of quarantine power?

---

## üìù Things We Explicitly Don't Address

1. **Legal Liability**: Who is responsible if an agent returns harmful data?
2. **Data Sovereignty**: Where is consumer/provider data stored and processed?
3. **Compliance**: GDPR, CCPA, industry-specific regulations
4. **Intellectual Property**: Can agents return copyrighted content?
5. **Content Moderation**: Who polices agent responses?
6. **Dispute Resolution**: What happens when consumer and provider disagree?
7. **Agent Ownership Transfer**: Can agents be sold or transferred?
8. **Sunset Policy**: How to gracefully retire agents?

---

## üîç Known Unknowns

Things we know we don't know:

1. **Optimal Ranking Algorithm**: Are the current weights (25/20/14/10/10/9/7/4/3) optimal?
2. **Fraud Detection Threshold**: Is 50% fraud percentage the right cutoff?
3. **Search Latency at Scale**: How does search perform with 1M+ agents?
4. **Economic Incentives**: Will a free registry attract quality providers?
5. **Network Effects**: How many agents needed for critical mass?

---

**This is not a roadmap. These are questions without clear answers.**
